# -*- coding: utf-8 -*-
"""
Created on Thu Jun 16 13:50:22 2022

@author: zfair
"""

import h5py
import datetime
#import contextily as cx
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import geopandas as gpd
import xarray as xr
from scipy.interpolate import RectBivariateSpline
#from xrspatial import hillshade, slope

#---------------#
def strong_beam_finder(sc_orient):
    """
    Identifies the strong beam ground tracks, based on space craft orientation.

    Parameters
    ----------
    sc_orient : int
        Identifier for spacecraft orientation.
            If sc_orient = 0 (BACKWARD), then the strong beams are the LEFT beams.
            If sc_orient = 1 (FORWARD), then the strong beams are the RIGHT beams.

    Returns
    -------
    strong_beams: list
        List of strings for ATL06/08 identifying the strong beam ground tracks.
    strongs_ids: list
        Same as strong_beams, but for ATL03SL

    """
    
    if sc_orient == 0:
        strong_beams = ['gt1l', 'gt2l', 'gt3l']
        strong_spots = ['1', '3', '5']
    elif sc_orient == 1:
        strong_beams = ['gt1r', 'gt2r', 'gt3r']
        strong_spots = ['5', '3', '1']
    else:
        raise ValueError('Invalid orientation - spacecraft may have been in' +
                         'transition phase')
    
    return strong_beams, strong_spots

#---------------#
def beam_cycle_concat(is2_files, product_id):
    """
    Organizes ATL06 and ATL08 data such that the beams (GT1X/GT2X/GT3X) are concatenated
    sequentially within a DataFrame. It is designed to mimic the output generated by SlideRule.

    Parameters
    ----------
    is2_files : list
        List of ATL06/08 files that are stored as strings.
    product_id: str
        Specifies whether the data is ATL06 or ATL08.
    strong_beams: list
        String identifiers for the strong beams, as found in strong_beam_finder()

    Returns
    -------
    concat_pd: DataFrame
        A concatenated DataFrame containing all repeat tracks and strong beams.

    """

    concat_pd = pd.DataFrame()
    for file in is2_files:
        with h5py.File(file, 'r') as f:
            # Grab only the strong beam data
            sc_orient = f['orbit_info/sc_orient'][0]
            strong_beams,strong_ids = strong_beam_finder(sc_orient)
            for idx,beam in enumerate(strong_beams):
                if product_id == 'ATL06':
                    try:
                        tmp = pd.DataFrame(data={'lat': f[beam+'/land_ice_segments/latitude'][:],
                                                 'lon': f[beam+'/land_ice_segments/longitude'][:],
                                                 'height': f[beam+'/land_ice_segments/h_li'][:],
                                                 'delta_time': f[beam+'/land_ice_segments/delta_time'][:],
                                                 'gt': strong_ids[idx]})
                    except:
                        print('Beam %s missing in data. Skipping concatenation...' %(beam))
                        tmp = pd.DataFrame()
                elif product_id == 'ATL08':
                    try:
                        tmp = pd.DataFrame(data={'lat': f[beam+'/land_segments/latitude'][:],
                                                 'lon': f[beam+'/land_segments/longitude'][:],
                                                 'height': f[beam+'/land_segments/terrain/h_te_best_fit'][:],
                                                 'delta_time': f[beam+'/land_segments/delta_time'][:],
                                                 'gt': strong_ids[idx]})
                    except:
                        print('Beam %s missing in data. Skipping concatenation...' %(beam))
                        tmp = pd.DataFrame()
                elif product_id == 'ATL12':
                    try:
                        tmp = pd.DataFrame(data={'lat': f[beam+'/ssh_segments/latitude'][:],
                                                 'lon': f[beam+'/ssh_segments/longitude'][:],
                                                 'height': f[beam+'/ssh_segments/heights/h'][:],
                                                 'delta_time': f[beam+'/ssh_segments/delta_time'][:],
                                                 'gt': strong_ids[idx]})
                    except:
                        print('Beam %s missing in data. Skipping concatenation...' %(beam))
                    
                concat_pd = pd.concat([concat_pd, tmp])
            
            
    
    # Generate the time column
    atlas_epoch = np.datetime64(datetime.datetime(2018,1,1))
    delta_time = (concat_pd['delta_time']*1e9).astype('timedelta64[ns]')
    concat_pd['time'] = gpd.pd.to_datetime(atlas_epoch + delta_time)
    
    # Set the datetime as the index
    #concat_pd.set_index('time', inplace=True)
    #concat_pd.sort_index(inplace=True)
    
    return concat_pd

#---------------#
def polyf(seri):
    """
    Generates a polynomial to estimate along-track slope. Slope is based on NEON heights.
    """
    
    return np.polyfit(seri.index.values, seri.values, 1)[0]

#---------------#
def coregister_is2(lidar_snow_off, lidar_snow_depth, is2_df):
    """
    Co-registers UAF lidar data with ICESat-2 data using a rectangular bivariate
    spline. The data is also corrected for geoid differences.
    This function likely be updated when other lidar or DEMs are considered.

    Parameters
    ----------
    lidar_snow_off : Xarray
        Lidar DEM/DTM in Xarray format.
    lidar_snow_depth : Xarray
        Lidar-derived snow depth in Xarray format.
    is2_df : DataFrame
        DataFrame for the ICESat-2 product of interest.

    Returns
    -------
    is2_lidar_pd : DataFrame
        Contains the coordinate and elevation data that matches best with
        ICESat-2.

    """
    
    # Define x/y coordinates from snow-off data
    x0, y0 = np.array(lidar_snow_off.x), np.array(lidar_snow_off.y)
    
    # Do the same, but for snow depth data (work in progress)
    xs, ys = np.array(lidar_snow_depth.x), np.array(lidar_snow_depth.y)
    
    # Filter NaNs that would otherwise mess up the interpolators
    dem_heights = np.array(lidar_snow_off.sel(band=1))[::-1,:]
    dem_heights[np.isnan(dem_heights)] = -9999
    dem_depths = np.array(lidar_snow_depth.sel(band=1))[::-1,:]
    dem_depths[np.isnan(dem_depths)] = -9999
    
    # Generate interpolators. UAF TIFFs are rarely the same size, hence the separate splines
    interp_height = RectBivariateSpline(np.array(y0)[::-1], 
                                        np.array(x0),
                                        dem_heights)
    interp_depth = RectBivariateSpline(np.array(ys)[::-1],
                                       np.array(xs),
                                       dem_depths)
    
    # Use the constructed spline to align the lidar with ICESat-2. This is done for all available beams.
    is2_lidar_df = pd.DataFrame()
    for beam in np.unique(is2_df['gt']):
        is2_tmp = is2_df.loc[is2_df['gt']==beam]
        
        # ICESat-2 x/y coordinates
        xn, yn = is2_tmp.geometry.x, is2_tmp.geometry.y
        
        # Define indices within x/y bounds of DEM
        i1 = (xn>np.min(x0)) & (xn<np.max(x0))
        i1 &= (yn>np.min(y0)) & (yn<np.max(y0))
        
        lidar_height = interp_height(yn[i1], xn[i1], grid=False)
        lidar_depth = interp_depth(yn[i1], xn[i1], grid=False)
        # Construct dataframe of ICESat-2 and UAF data.
        try: # SlideRule (ATL06-SR)
            tmp = pd.DataFrame(data={'lat': is2_tmp['lat'][i1],
                                     'lon': is2_tmp['lon'][i1],
                                     'x': xn[i1],
                                     'y': yn[i1],
                                     'rgt': is2_tmp['rgt'][i1],
                                     'beam': is2_tmp['gt'][i1],
                                     'is2_height': is2_tmp['height'][i1],
                                     'n_fit_photons': is2_tmp['n_fit_photons'][i1],
                                     'h_sigma': is2_tmp['h_sigma'][i1],
                                     'dh_fit_dx': is2_tmp['dh_fit_dx'][i1],
                                     'lidar_height': lidar_height,
                                     'lidar_snow_depth': lidar_depth
                                    }
                              )
        except: # ATL06 and ATL08
            tmp = pd.DataFrame(data={'lat': is2_tmp['lat'][i1],
                                     'lon': is2_tmp['lon'][i1],
                                     'x': xn[i1],
                                     'y': yn[i1],
                                     'beam': is2_tmp['gt'][i1],
                                     'is2_height': is2_tmp['height'][i1],
                                     'lidar_height': lidar_height,
                                     'lidar_snow_depth': lidar_depth
                                    }
                              )
            
        # Concatenate coregistered data to final dataframe
        is2_lidar_df = pd.concat([is2_lidar_df, tmp])

        # Estimate the ICESat-2 residual (e.g. snow depth during snow-on)
        is2_lidar_df['residual'] = is2_lidar_df['is2_height'] - is2_lidar_df['lidar_height']
        
    # Convert final dataframe into a geodataframe
    is2_lidar_gdf = gpd.GeoDataFrame(is2_lidar_df,
                                     geometry=gpd.points_from_xy(is2_lidar_df.lon, is2_lidar_df.lat),
                                     crs='EPSG:4326')
    
    return is2_lidar_gdf


#---------------#
def coregister_3dep(ds_3dep, is2_df):
    """
    Same as coregister_is2, but designed for 3DEP 10-meter mosaics gathered using
    py3dep.

    Parameters
    ----------
    ds_3dep: Xarray
        3DEP DataArray for snow-off elevation.
    is2_df: DataFrame
        (geo)pandas dataframe containing ICESat-2 data to co-locate with 3DEP.

    Returns
    -------
    is2_3dep_df: GeoDataFrame
        GeoDataFrame containing the co-located ICESat-2 and 3DEP lidar data.
        
    """
    # Define x/y coordinates from snow-off data
    x0, y0 = np.array(ds_3dep.x), np.array(ds_3dep.y)
    
    # Filter NaNs that would otherwise mess up the interpolators
    dem_heights = np.array(ds_3dep)[::-1,:]
    dem_heights[np.isnan(dem_heights)] = -9999
    
    # Generate interpolators. UAF TIFFs are rarely the same size, hence the separate splines
    interp_height = RectBivariateSpline(np.array(y0)[::-1], 
                                        np.array(x0),
                                        dem_heights)
    
    # Use the constructed spline to align the lidar with ICESat-2. This is done for all available beams.
    is2_lidar_df = pd.DataFrame()
    for beam in np.unique(is2_df['gt']):
        is2_tmp = is2_df.loc[is2_df['gt']==beam]
        
        # ICESat-2 x/y coordinates
        xn, yn = is2_tmp.geometry.x, is2_tmp.geometry.y
        
        # Define indices within x/y bounds of DEM
        i1 = (xn>np.min(x0)) & (xn<np.max(x0))
        i1 &= (yn>np.min(y0)) & (yn<np.max(y0))
        
        lidar_height = interp_height(yn[i1], xn[i1], grid=False)
        # Construct dataframe of ICESat-2 and UAF data.
        try: # SlideRule (ATL06-SR)
            tmp = pd.DataFrame(data={'lat': is2_tmp['lat'][i1],
                                     'lon': is2_tmp['lon'][i1],
                                     'x': xn[i1],
                                     'y': yn[i1],
                                     'rgt': is2_tmp['rgt'][i1],
                                     'beam': is2_tmp['gt'][i1],
                                     'is2_height': is2_tmp['height'][i1],
                                     'n_fit_photons': is2_tmp['n_fit_photons'][i1],
                                     'h_sigma': is2_tmp['h_sigma'][i1],
                                     'dh_fit_dx': is2_tmp['dh_fit_dx'][i1],
                                     'lidar_height': lidar_height
                                    }
                              )
        except: # ATL06 and ATL08
            tmp = pd.DataFrame(data={'lat': is2_tmp['lat'][i1],
                                     'lon': is2_tmp['lon'][i1],
                                     'x': xn[i1],
                                     'y': yn[i1],
                                     'beam': is2_tmp['gt'][i1],
                                     'is2_height': is2_tmp['height'][i1],
                                     'lidar_height': lidar_height
                                    }
                              )
            
        # Concatenate coregistered data to final dataframe
        is2_lidar_df = pd.concat([is2_lidar_df, tmp])

        # Estimate the ICESat-2 residual (e.g. snow depth during snow-on)
        is2_lidar_df['residual'] = is2_lidar_df['is2_height'] - is2_lidar_df['lidar_height']
        
    # Convert final dataframe into a geodataframe
    is2_lidar_gdf = gpd.GeoDataFrame(is2_lidar_df,
                                     geometry=gpd.points_from_xy(is2_lidar_df.lon, is2_lidar_df.lat),
                                     crs='EPSG:4326')
    
    return is2_lidar_gdf

#---------------#
def coregister_point_data(lidar_tif, lidar_snow_depth, ground_pd):
    """
    Same as coregister_neon (which needs a more generic name), but matches
    a lidar DEM with ground-based data instead. Currently configured for BSU GPR
    and ASO over Grand Mesa.

    Parameters
    ----------
    lidar_tif : Xarray
        The lidar in Xarray format. Can be surface elevation or snow depth.
    ground_pd : DataFrame
        DataFrame for ground-based data of interest. Should include easting/northing
        coordinates, surface elevation, and/or snow depth.

    Returns
    -------
    ground_lidar_pd : DataFrame
        Co-registered lidar and ground-based data, using spline interpolation.

    """
    
    # Correction factor to reproject lidar data to WGS84. Currently only
    # have a value for NEON.
    # A GEOID CORRECTION FOR ASO IS NEEDED ASAP
    geoid_correction = 9.95
    
    x0 = np.array(lidar_tif.x)
    y0 = np.array(lidar_tif.y)
    
    # Apply spline to NEON data
    dem_heights = np.array(lidar_tif.sel(band=1))[::-1,:]
    dem_heights[np.isnan(dem_heights)] = -9999
    interpolator = RectBivariateSpline(np.array(y0)[::-1], 
                                       np.array(x0),
                                       dem_heights)
    
    snow_depths = np.array(lidar_snow_depth.sel(band=1))[::-1,:]
    snow_depths[np.isnan(snow_depths)] = -9999
    interpolator2 = RectBivariateSpline(np.array(y0)[::-1],
                                       np.array(x0),
                                       snow_depths)
    
    
    # Use the constructed spline to align NEON with ICESat-2. This is done for
    # all three strong beams.
    ground_lidar_pd = pd.DataFrame()
    if 'PitID' in ground_pd.columns:
        for ID in np.unique(ground_pd['PitID']):
            tmp_pd = ground_pd.loc[ground_pd.PitID==ID]
            
            xn = tmp_pd['Easting'].values
            yn = tmp_pd['Northing'].values
            
            i1 = (xn>np.min(x0)) & (xn<np.max(x0))
            i1 &= (yn>np.min(y0)) & (yn<np.max(y0))
            
            x, y = xn[i1], yn[i1]
            lidar_height = interpolator(yn[i1], xn[i1], grid=False)
            lidar_snow_depth = interpolator2(yn[i1], xn[i1], grid=False)
            ground_height = tmp_pd['Elevation'][i1]
            doy = tmp_pd['UTCdoy'][i1]
            ground_snow_depth = tmp_pd['Depth'][i1]
            
            # Construct co-registered dataframe (NEEDS TO INCLUDE ALL BEAMS AND TIMES)
            tmp = pd.DataFrame(data={'doy':doy,
                                     'x': x,
                                     'y': y,
                                     'lidar_height': lidar_height,
                                     'lidar_snow_depth': lidar_snow_depth,
                                     'ground_height': ground_height,
                                     'ground_snow_depth': ground_snow_depth})
            
            ground_lidar_pd = pd.concat([ground_lidar_pd, tmp])
    else:
        xn = ground_pd['Easting'].values
        yn = ground_pd['Northing'].values
        
        #Define indices within x/y bounds
        i1 = (xn>np.min(x0)) & (xn<np.max(x0))
        i1 &= (yn>np.min(y0)) & (yn<np.max(y0))
        
        # Set x/y coordinates, NEON heights, and corresponding IS-2 heights
        x, y = xn[i1], yn[i1]
        lidar_height = interpolator(yn[i1], xn[i1], grid=False)
        lidar_snow_depth = interpolator2(yn[i1], xn[i1], grid=False)
        ground_height = ground_pd['Elevation'][i1]
        doy = ground_pd['UTCdoy'][i1]
        ground_snow_depth = ground_pd['Depth'][i1]

        
        # Construct co-registered dataframe (NEEDS TO INCLUDE ALL BEAMS AND TIMES)
        tmp = pd.DataFrame(data={'doy':doy,
                                 'x': x,
                                 'y': y,
                                 'lidar_height': lidar_height,
                                 'lidar_snow_depth': lidar_snow_depth,
                                 'ground_height': ground_height,
                                 'ground_snow_depth': ground_snow_depth})
        
        ground_lidar_pd = pd.concat([ground_lidar_pd, tmp])
    
        
    # Apply correction factor to NEON data
    ground_lidar_pd['lidar_height'] += geoid_correction
    ground_lidar_pd['residual'] = ground_lidar_pd['ground_height'] - ground_lidar_pd['lidar_height']
    ground_lidar_pd['slope'] = ground_lidar_pd['ground_height'].rolling(10, min_periods=2).apply(polyf, raw=False)
    
    return ground_lidar_pd

#---------------#
def coregister_land_cover_data(is2_pd, land_cover_map, strong_ids):
    
    # Surface elevation coordinates
    x0 = np.array(land_cover_map.x)
    y0 = np.array(land_cover_map.y)
    
    # Apply spline to NEON data
    lc = np.array(land_cover_map.sel(band=1))
    interpolator = RectBivariateSpline(np.array(y0)[::-1], 
                                       np.array(x0),
                                       lc)
    
    # Use the constructed spline to align NEON with ICESat-2. This is done for
    # all three strong beams.
    lc_pd = pd.DataFrame()
    for spot in strong_ids:
        if not 'spot' in is2_pd.columns:
            is2_tmp = is2_pd.loc[is2_pd['gt']==spot]
            
            xn = is2_tmp['x'].values
            yn = is2_tmp['y'].values
            
            #Define indices within x/y bounds of DEM
            i1 = (xn>np.min(x0)) & (xn<np.max(x0))
            i1 &= (yn>np.min(y0)) & (yn<np.max(y0))
            
            # Set x/y coordinates, NEON heights, and corresponding IS-2 heights
            x, y = xn[i1], yn[i1]
            land_cover = interpolator(yn[i1], xn[i1], grid=False)
        else:
            is2_tmp = is2_pd.loc[is2_pd['spot']==spot]
            
            xn = is2_tmp['x'].values
            yn = is2_tmp['y'].values
            
            #Define indices within x/y bounds
            i1 = (xn>np.min(x0)) & (xn<np.max(x0))
            i1 &= (yn>np.min(y0)) & (yn<np.max(y0))
            
            # Set x/y coordinates, NEON heights, and corresponding IS-2 heights
            x, y = xn[i1], yn[i1]
            land_cover = interpolator(yn[i1], xn[i1], grid=False)
            
            # Construct co-registered dataframe (NEEDS TO INCLUDE ALL BEAMS AND TIMES)
            tmp = pd.DataFrame(data={'x': x,
                                     'y': y,
                                     'land_cover': land_cover})
                
            lc_pd = pd.concat([lc_pd, tmp])
            
    return lc_pd


#---------------#
def make_snow_map(ground_lidar_pd, bbox, epsg_code):
    """
    Uses contextily to make a map of snow depth or data differences from the
    ground data.

    Parameters
    ----------
    ground_lidar_pd : DataFrame
        Co-registered ground/ASO/Quantum data.
    bbox : list
        The SW/NE coordinates, in [SW_lon, SW_lat, NE_lon, NE_lat] format.
    epsg_code : float/int
        EPSG number for desired horizontal projection.

    Returns
    -------
    snow_map : axis object
        Mapped ground data.

    """
    
    # Set bounding box
    west,south,east,north = (bbox[0],
                             bbox[1],
                             bbox[2],
                             bbox[3])
    
    # Construct contextily map
    img, shp = cx.bounds2img(west,
                             south,
                             east,
                             north,
                             ll=True,
                             source=cx.providers.USGS.USImageryTopo)
    
    # Convert to desired projection
    img, shp = cx.warp_tiles(img, shp, 'epsg:{}'.format(epsg_code))
    
    snow_map = plt.imshow(img, extent=shp)
    
    return snow_map

#---------------#
def generate_lidar_hillshade(lidar_tif):
    """
    Takes a lidar DEM/DSM/DTM and generates a shaded relief map. Applicable
    to any lidar data saved as a tif and loaded into Xarray.

    Parameters
    ----------
    lidar_tif : DataArray
        The lidar elevation data, given as a DEM/DTM/DSM. Horizontal
        and vertical datum transformations should not be necessary. 

    Returns
    -------
    lidar_hillshade : DataArray
        The shaded relief map, using the hillshade technique.

    """
    
    lidar_hillshade = hillshade(lidar_tif.isel(band=0))
    lidar_slope = slope(lidar_tif.isel(band=0))
    
    return lidar_hillshade, lidar_slope